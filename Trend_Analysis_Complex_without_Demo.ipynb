{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MySQL to perform exploratory data analysis\n",
    "import settings\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#%matplotlib inline\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "py.init_notebook_mode()\n",
    "    \n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Filter constants for states in US\n",
    "STATES = ['Alabama', 'AL', 'Alaska', 'AK', 'American Samoa', 'AS', 'Arizona', 'AZ', 'Arkansas', 'AR', 'California', 'CA', 'Colorado', 'CO', 'Connecticut', 'CT', 'Delaware', 'DE', 'District of Columbia', 'DC', 'Federated States of Micronesia', 'FM', 'Florida', 'FL', 'Georgia', 'GA', 'Guam', 'GU', 'Hawaii', 'HI', 'Idaho', 'ID', 'Illinois', 'IL', 'Indiana', 'IN', 'Iowa', 'IA', 'Kansas', 'KS', 'Kentucky', 'KY', 'Louisiana', 'LA', 'Maine', 'ME', 'Marshall Islands', 'MH', 'Maryland', 'MD', 'Massachusetts', 'MA', 'Michigan', 'MI', 'Minnesota', 'MN', 'Mississippi', 'MS', 'Missouri', 'MO', 'Montana', 'MT', 'Nebraska', 'NE', 'Nevada', 'NV', 'New Hampshire', 'NH', 'New Jersey', 'NJ', 'New Mexico', 'NM', 'New York', 'NY', 'North Carolina', 'NC', 'North Dakota', 'ND', 'Northern Mariana Islands', 'MP', 'Ohio', 'OH', 'Oklahoma', 'OK', 'Oregon', 'OR', 'Palau', 'PW', 'Pennsylvania', 'PA', 'Puerto Rico', 'PR', 'Rhode Island', 'RI', 'South Carolina', 'SC', 'South Dakota', 'SD', 'Tennessee', 'TN', 'Texas', 'TX', 'Utah', 'UT', 'Vermont', 'VT', 'Virgin Islands', 'VI', 'Virginia', 'VA', 'Washington', 'WA', 'West Virginia', 'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']\n",
    "STATE_DICT = dict(itertools.zip_longest(*[iter(STATES)] * 2, fillvalue=\"\"))\n",
    "INV_STATE_DICT = dict((v,k) for k,v in STATE_DICT.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This complex plot shows the latest Twitter data within 30 mins and will automatically update.\n",
    "'''\n",
    "while True:\n",
    "    clear_output()\n",
    "    db_connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        passwd=\"password\",\n",
    "        database=\"TwitterDB\",\n",
    "        charset = 'utf8'\n",
    "    )\n",
    "    # Load data from MySQL\n",
    "    timenow = (datetime.datetime.utcnow() - datetime.timedelta(hours=0, minutes=30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    query = \"SELECT id_str, text, created_at, polarity, user_location FROM {} WHERE created_at >= '{}' \" \\\n",
    "                     .format(settings.TABLE_NAME, timenow)\n",
    "    df = pd.read_sql(query, con=db_connection)\n",
    "    # UTC for date time at default\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        column_widths=[1, 0.4],\n",
    "        row_heights=[0.6, 0.4],\n",
    "        specs=[[{\"type\": \"scatter\", \"rowspan\": 2}, {\"type\": \"choropleth\"}],\n",
    "               [            None                    , {\"type\": \"bar\"}]]\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Plot the Line Chart\n",
    "    '''\n",
    "    # Clean and transform data to enable time series\n",
    "    result = df.groupby([pd.Grouper(key='created_at', freq='30s'), 'polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "    result = result.rename(columns={\"id_str\": \"Num of '{}' mentions\".format(settings.TRACK_WORDS[0]), \"created_at\":\"Time in UTC\"})  \n",
    "    time_series = result[\"Time in UTC\"][result['polarity']==0].reset_index(drop=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].reset_index(drop=True),\n",
    "        name=\"Neural\",\n",
    "        opacity=0.8), row=1, col=1)   \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==-1].reset_index(drop=True),\n",
    "        name=\"Negative\",\n",
    "        opacity=0.8), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==1].reset_index(drop=True),\n",
    "        name=\"Positive\",\n",
    "        opacity=0.8), row=1, col=1)\n",
    "    \n",
    "    '''\n",
    "    Plot the Bar Chart\n",
    "    '''\n",
    "    content = ' '.join(df[\"text\"])\n",
    "    content = re.sub(r\"http\\S+\", \"\", content)\n",
    "    content = content.replace('RT ', ' ').replace('&amp;', 'and')\n",
    "    content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "    content = content.lower()\n",
    "\n",
    "    tokenized_word = word_tokenize(content)\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_sent=[]\n",
    "    for w in tokenized_word:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "    fdist = FreqDist(filtered_sent)\n",
    "    fd = pd.DataFrame(fdist.most_common(10), columns = [\"Word\",\"Frequency\"]).drop([0]).reindex()\n",
    "    \n",
    "    # Plot Bar chart   \n",
    "    fig.add_trace(go.Bar(x=fd[\"Word\"], y=fd[\"Frequency\"], name=\"Freq Dist\"), row=2, col=2)\n",
    "    # 59, 89, 152\n",
    "    fig.update_traces(marker_color='rgb(59, 89, 152)', marker_line_color='rgb(8,48,107)', \\\n",
    "            marker_line_width=0.5, opacity=0.7, row=2, col=2)\n",
    "    \n",
    "    '''\n",
    "    Plot the Geo-Distribution\n",
    "    '''\n",
    "    is_in_US=[]\n",
    "    geo = df[['user_location']]\n",
    "    df = df.fillna(\" \")\n",
    "    for x in df['user_location']:\n",
    "        check = False\n",
    "        for s in STATES:\n",
    "            if s in x:\n",
    "                is_in_US.append(STATE_DICT[s] if s in STATE_DICT else s)\n",
    "                check = True\n",
    "                break\n",
    "        if not check:\n",
    "            is_in_US.append(None)\n",
    "\n",
    "    geo_dist = pd.DataFrame(is_in_US, columns=['State']).dropna().reset_index()\n",
    "    geo_dist = geo_dist.groupby('State').count().rename(columns={\"index\": \"Number\"}) \\\n",
    "            .sort_values(by=['Number'], ascending=False).reset_index()\n",
    "    geo_dist[\"Log Num\"] = geo_dist[\"Number\"].apply(lambda x: math.log(x, 2))\n",
    "\n",
    "\n",
    "    geo_dist['Full State Name'] = geo_dist['State'].apply(lambda x: INV_STATE_DICT[x])\n",
    "    geo_dist['text'] = geo_dist['Full State Name'] + '<br>' + 'Num: ' + geo_dist['Number'].astype(str)\n",
    "    fig.add_trace(go.Choropleth(\n",
    "        locations=geo_dist['State'], # Spatial coordinates\n",
    "        z = geo_dist['Log Num'].astype(float), # Data to be color-coded\n",
    "        locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "        colorscale = \"Blues\",\n",
    "        text=geo_dist['text'], # hover text\n",
    "        showscale=False,\n",
    "        geo = 'geo'\n",
    "        ),\n",
    "        row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text= \"Real-time tracking '{}' mentions on Twitter {} UTC\".format(settings.TRACK_WORDS[0] ,datetime.datetime.utcnow().strftime('%m-%d %H:%M')),\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "        ),\n",
    "        template=\"plotly_dark\",\n",
    "        margin=dict(r=20, t=50, b=50, l=20),\n",
    "        annotations=[\n",
    "            go.layout.Annotation(\n",
    "                text=\"Source: Twitter\",\n",
    "                showarrow=False,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                x=0,\n",
    "                y=0)\n",
    "        ],\n",
    "        showlegend=False,\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "         \n",
    "    fig.show()\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
